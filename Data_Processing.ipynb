{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Final Project\n",
    "\n",
    "Group 5\n",
    "\n",
    "course: SEP 775 - Introduction to Computational Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pymupdf\n",
    "import re\n",
    "import os\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files in the folder: 51\n",
      "Attention Is All You Need.pdf\n",
      "BERT- Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf\n",
      "BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION.pdf\n",
      "BLEU- a Method for Automatic Evaluation of Machine Translation.pdf\n",
      "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf\n",
      "Contextual Word Representations- A Contextual Introduction.pdf\n",
      "Dense Passage Retrieval for Open-Domain Question Answering.pdf\n",
      "Distributed Representations of Words and Phrases and their Compositionality.pdf\n",
      "Efficient Estimation of Word Representations in Vector Space.pdf\n",
      "Evaluation methods for unsupervised word embeddings.pdf\n",
      "FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS.pdf\n",
      "Fine-Tuning and Masked Language Models.pdf\n",
      "GloVe- Global Vectors for Word Representation.pdf\n",
      "Image Transformer.pdf\n",
      "Improving Distributional Similarity with Lessons Learned from Word Embeddings.pdf\n",
      "Language Models are Few-Shot Learners.pdf\n",
      "Latent Retrieval for Weakly Supervised Open Domain Question Answering.pdf\n",
      "Layer Normalization.pdf\n",
      "Learning Dense Representations of Phrases at Scale.pdf\n",
      "Learning to summarize from human feedback.pdf\n",
      "MUSIC TRANSFORMER- GENERATING MUSIC WITH LONG-TERM STRUCTURE.pdf\n",
      "N-gram Language Models.pdf\n",
      "NLP - Winter 2024 - Course Outline.pdf\n"
     ]
    }
   ],
   "source": [
    "# check files in the folder\n",
    "# all materials including the notes, slides, assignments, papers, etc.\n",
    "avenue2learn_path = './materials_avenue2learn_and_notes/'\n",
    "avenue2learn_files = os.listdir(avenue2learn_path)\n",
    "avenue2learn_files = [f for f in avenue2learn_files if f.endswith('.pdf')]\n",
    "\n",
    "print('the number of files in the folder:', len(avenue2learn_files))\n",
    "avenue2learn_files.sort()\n",
    "count = 0\n",
    "for file in avenue2learn_files:\n",
    "    count += 1\n",
    "    if count < 24:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files in the folder: 51\n",
      "Attention_Is_All_You_Need.txt\n",
      "BERT_Pre_training_of_Deep_Bidirectional_Transformers_for_Language_Understanding.txt\n",
      "BI_DIRECTIONAL_ATTENTION_FLOW_FOR_MACHINE_COMPREHENSION.txt\n",
      "BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation.txt\n",
      "Chain_of_Thought_Prompting_Elicits_Reasoning_in_Large_Language_Models.txt\n",
      "Contextual_Word_Representations_A_Contextual_Introduction.txt\n",
      "Dense_Passage_Retrieval_for_Open_Domain_Question_Answering.txt\n",
      "Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.txt\n",
      "Efficient_Estimation_of_Word_Representations_in_Vector_Space.txt\n",
      "Evaluation_methods_for_unsupervised_word_embeddings.txt\n",
      "FINETUNED_LANGUAGE_MODELS_ARE_ZERO_SHOT_LEARNERS.txt\n",
      "Fine_Tuning_and_Masked_Language_Models.txt\n",
      "GloVe_Global_Vectors_for_Word_Representation.txt\n",
      "Image_Transformer.txt\n",
      "Improving_Distributional_Similarity_with_Lessons_Learned_from_Word_Embeddings.txt\n",
      "Language_Models_are_Few_Shot_Learners.txt\n",
      "Latent_Retrieval_for_Weakly_Supervised_Open_Domain_Question_Answering.txt\n",
      "Layer_Normalization.txt\n",
      "Learning_Dense_Representations_of_Phrases_at_Scale.txt\n",
      "Learning_to_summarize_from_human_feedback.txt\n",
      "MUSIC_TRANSFORMER_GENERATING_MUSIC_WITH_LONG_TERM_STRUCTURE.txt\n",
      "NLP_Winter_2024_Course_Outline.txt\n",
      "N_gram_Language_Models.txt\n",
      "Natural_Language_Processing_Almost_from_Scratch.txt\n"
     ]
    }
   ],
   "source": [
    "# check files in the folder\n",
    "# all materials including the notes, slides, assignments, papers, etc.\n",
    "avenue2learn_path = './output/'\n",
    "avenue2learn_files = os.listdir(avenue2learn_path)\n",
    "\n",
    "print('the number of files in the folder:', len(avenue2learn_files))\n",
    "avenue2learn_files.sort()\n",
    "count = 0\n",
    "for file in avenue2learn_files:\n",
    "    count += 1\n",
    "    if count <= 24:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted SQuAD_100_000_Questions_for_Machine_Comprehension_of_Text.pdf to ./output/SQuAD_100_000_Questions_for_Machine_Comprehension_of_Text.txt\n",
      "Converted lecture09_Multimodal_Models.pdf to ./output/lecture09_Multimodal_Models.txt\n",
      "Converted Understanding_LSTM_Networks.pdf to ./output/Understanding_LSTM_Networks.txt\n",
      "Converted Reading_Wikipedia_to_Answer_Open_Domain_Questions.pdf to ./output/Reading_Wikipedia_to_Answer_Open_Domain_Questions.txt\n",
      "Converted lecture06_notes_self_attention_transformers.pdf to ./output/lecture06_notes_self_attention_transformers.txt\n",
      "Converted Efficient_Estimation_of_Word_Representations_in_Vector_Space.pdf to ./output/Efficient_Estimation_of_Word_Representations_in_Vector_Space.txt\n",
      "Converted lecture08_Question_Answering.pdf to ./output/lecture08_Question_Answering.txt\n",
      "Converted lecture03_notes_LM_RNN.pdf to ./output/lecture03_notes_LM_RNN.txt\n",
      "Converted NLP_Winter_2024_Course_Outline.pdf to ./output/NLP_Winter_2024_Course_Outline.txt\n",
      "Converted lecture01_wordvecs1.pdf to ./output/lecture01_wordvecs1.txt\n",
      "Converted lecture03_notes_dependencyparsing.pdf to ./output/lecture03_notes_dependencyparsing.txt\n",
      "Converted Dense_Passage_Retrieval_for_Open_Domain_Question_Answering.pdf to ./output/Dense_Passage_Retrieval_for_Open_Domain_Question_Answering.txt\n",
      "Converted SEP775_Assignment4.pdf to ./output/SEP775_Assignment4.txt\n",
      "Converted Chain_of_Thought_Prompting_Elicits_Reasoning_in_Large_Language_Models.pdf to ./output/Chain_of_Thought_Prompting_Elicits_Reasoning_in_Large_Language_Models.txt\n",
      "Converted lecture06_Transformers.pdf to ./output/lecture06_Transformers.txt\n",
      "Converted Latent_Retrieval_for_Weakly_Supervised_Open_Domain_Question_Answering.pdf to ./output/Latent_Retrieval_for_Weakly_Supervised_Open_Domain_Question_Answering.txt\n",
      "Converted BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation.pdf to ./output/BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation.txt\n",
      "Converted SEP775_FinalProjects_2.pdf to ./output/SEP775_FinalProjects_2.txt\n",
      "Converted gradient_notes.pdf to ./output/gradient_notes.txt\n",
      "Converted SEP775_Assignment1.pdf to ./output/SEP775_Assignment1.txt\n",
      "Converted Evaluation_methods_for_unsupervised_word_embeddings.pdf to ./output/Evaluation_methods_for_unsupervised_word_embeddings.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1138 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Learning_to_summarize_from_human_feedback.pdf to ./output/Learning_to_summarize_from_human_feedback.txt\n",
      "Converted SEP775_Assignment2.pdf to ./output/SEP775_Assignment2.txt\n",
      "Converted Learning_Dense_Representations_of_Phrases_at_Scale.pdf to ./output/Learning_Dense_Representations_of_Phrases_at_Scale.txt\n",
      "Converted Image_Transformer.pdf to ./output/Image_Transformer.txt\n",
      "Converted SEP775_Assignment3.pdf to ./output/SEP775_Assignment3.txt\n",
      "Converted GloVe_Global_Vectors_for_Word_Representation.pdf to ./output/GloVe_Global_Vectors_for_Word_Representation.txt\n",
      "Converted MUSIC_TRANSFORMER_GENERATING_MUSIC_WITH_LONG_TERM_STRUCTURE.pdf to ./output/MUSIC_TRANSFORMER_GENERATING_MUSIC_WITH_LONG_TERM_STRUCTURE.txt\n",
      "Converted On_the_difficulty_of_training_Recurrent_Neural_Networks.pdf to ./output/On_the_difficulty_of_training_Recurrent_Neural_Networks.txt\n",
      "Converted lecture01_notes_Introduction.pdf to ./output/lecture01_notes_Introduction.txt\n",
      "Converted SEP775_python_review_2024.pdf to ./output/SEP775_python_review_2024.txt\n",
      "Converted Fine_Tuning_and_Masked_Language_Models.pdf to ./output/Fine_Tuning_and_Masked_Language_Models.txt\n",
      "Converted lecture05_Seq2Seq.pdf to ./output/lecture05_Seq2Seq.txt\n",
      "Converted Improving_Distributional_Similarity_with_Lessons_Learned_from_Word_Embeddings.pdf to ./output/Improving_Distributional_Similarity_with_Lessons_Learned_from_Word_Embeddings.txt\n",
      "Converted Language_Models_are_Few_Shot_Learners.pdf to ./output/Language_Models_are_Few_Shot_Learners.txt\n",
      "Converted FINETUNED_LANGUAGE_MODELS_ARE_ZERO_SHOT_LEARNERS.pdf to ./output/FINETUNED_LANGUAGE_MODELS_ARE_ZERO_SHOT_LEARNERS.txt\n",
      "Converted BI_DIRECTIONAL_ATTENTION_FLOW_FOR_MACHINE_COMPREHENSION.pdf to ./output/BI_DIRECTIONAL_ATTENTION_FLOW_FOR_MACHINE_COMPREHENSION.txt\n",
      "Converted lecture02_notes_Backpropagation.pdf to ./output/lecture02_notes_Backpropagation.txt\n",
      "Converted BERT_Pre_training_of_Deep_Bidirectional_Transformers_for_Language_Understanding.pdf to ./output/BERT_Pre_training_of_Deep_Bidirectional_Transformers_for_Language_Understanding.txt\n",
      "Converted lecture07_Prompting_Instruction_Finetuning_and_RLHF_.pdf to ./output/lecture07_Prompting_Instruction_Finetuning_and_RLHF_.txt\n",
      "Converted Contextual_Word_Representations_A_Contextual_Introduction.pdf to ./output/Contextual_Word_Representations_A_Contextual_Introduction.txt\n",
      "Converted SEP775_CodingExercise.pdf to ./output/SEP775_CodingExercise.txt\n",
      "Converted Layer_Normalization.pdf to ./output/Layer_Normalization.txt\n",
      "Converted Natural_Language_Processing_Almost_from_Scratch.pdf to ./output/Natural_Language_Processing_Almost_from_Scratch.txt\n",
      "Converted N_gram_Language_Models.pdf to ./output/N_gram_Language_Models.txt\n",
      "Converted Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.pdf to ./output/Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.txt\n",
      "Converted lecture04_Conditioned_Generation.pdf to ./output/lecture04_Conditioned_Generation.txt\n",
      "Converted lecture02_Neural_Nets.pdf to ./output/lecture02_Neural_Nets.txt\n",
      "Converted lecture01_notes_wordvecs2.pdf to ./output/lecture01_notes_wordvecs2.txt\n",
      "Converted Attention_Is_All_You_Need.pdf to ./output/Attention_Is_All_You_Need.txt\n",
      "Converted lecture03_RNNs_and_LLMs.pdf to ./output/lecture03_RNNs_and_LLMs.txt\n"
     ]
    }
   ],
   "source": [
    "def convert_pdf_to_text(file_path, output_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    out = open(output_path, \"wb\")\n",
    "    for page in doc:\n",
    "        text = page.get_text().encode(\"utf8\")\n",
    "        # remove special characters and replace with space except for \\n, @, and .\n",
    "        text = re.sub(r'[^\\w\\s\\n@\\.]', ' ', text.decode(\"utf8\"))\n",
    "        # remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # remove empty lines\n",
    "        text = re.sub(r'\\n\\s*\\n', '', text)\n",
    "        # remove new lines\n",
    "        text = re.sub(r'\\n', '', text)\n",
    "        # remove leading and trailing spaces\n",
    "        text = text.strip()\n",
    "\n",
    "        text = re.sub(r'draft note 1 introduction and word2vec cs 224n natural language processing with deep learning \\d+', '', text)\n",
    "        text = re.sub(r'cs224n natural language processing with deep learning lecture notes part ii word vectors ii glove evaluation and training \\d+', '', text)\n",
    "        text = re.sub(r'cs224n natural language processing with deep learning lecture notes part iii neural networks backpropagation \\d+', '', text)\n",
    "        text = re.sub(r'cs224n natural language processing with deep learning lecture notes part iv dependency parsing \\d+', '', text)\n",
    "        text = re.sub(r'cs224n natural language processing with deep learning lecture notes part v language models rnn gru and lstm \\d+', '', text)\n",
    "        text = re.sub(r'draft note 10 self attention transformers cs 224n natural language processing with deep learning \\d+', '', text)\n",
    "\n",
    "        # find \"Keyphrases\" and remove everything before it\n",
    "        keyphrases = re.search(r'Keyphrases', text)\n",
    "        if keyphrases:\n",
    "            text = text[keyphrases.end():]\n",
    "\n",
    "        # find \"Winter 2023 Summary.\" and remove everything before it\n",
    "        winter_summary = re.search(r'Winter 2023 Summary.', text)\n",
    "        if winter_summary:\n",
    "            text = text[winter_summary.end():]\n",
    "\n",
    "        # remove all new lines\n",
    "        text = re.sub(r'\\n+', '', text)\n",
    "\n",
    "        #convert text back to bytes\n",
    "        text = text.encode(\"utf8\")\n",
    "\n",
    "        out.write(text)\n",
    "        out.write(bytes((10,))) # write \\n\\n to separate pages\n",
    "    out.close()\n",
    "\n",
    "def convert_pdfs_to_text_files(file_path_dir, output_dir):\n",
    "    files = os.listdir(file_path_dir)\n",
    "    files = [f for f in files if f.endswith('.pdf')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(file_path_dir, file)\n",
    "        file = re.sub(r'\\s', '_', file)\n",
    "        # replace special characters with underscore except for .pdf\n",
    "        file = re.sub(r'[^\\w\\.]', '_', file)\n",
    "        # replace multiple underscores with one\n",
    "        file = re.sub(r'_+', '_', file)\n",
    "        output_path = os.path.join(output_dir, file.replace('.pdf', '.txt'))\n",
    "        convert_pdf_to_text(file_path, output_path)\n",
    "        print(f'Converted {file} to {output_path}')\n",
    "\n",
    "convert_pdfs_to_text_files(avenue2learn_path, './output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed new lines from lecture09_Multimodal_Models.txt\n",
      "Removed new lines from lecture01_notes_Introduction.txt\n",
      "Removed new lines from SEP775_Assignment4.txt\n",
      "Removed new lines from GloVe_Global_Vectors_for_Word_Representation.txt\n",
      "Removed new lines from lecture05_Seq2Seq.txt\n",
      "Removed new lines from gradient_notes.txt\n",
      "Removed new lines from lecture03_notes_LM_RNN.txt\n",
      "Removed new lines from SEP775_Assignment2.txt\n",
      "Removed new lines from lecture02_notes_Backpropagation.txt\n",
      "Removed new lines from Learning_to_summarize_from_human_feedback.txt\n",
      "Removed new lines from SEP775_python_review_2024.txt\n",
      "Removed new lines from lecture01_wordvecs1.txt\n",
      "Removed new lines from Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.txt\n",
      "Removed new lines from SEP775_Assignment3.txt\n",
      "Removed new lines from Improving_Distributional_Similarity_with_Lessons_Learned_from_Word_Embeddings.txt\n",
      "Removed new lines from On_the_difficulty_of_training_Recurrent_Neural_Networks.txt\n",
      "Removed new lines from SEP775_Assignment1.txt\n",
      "Removed new lines from N_gram_Language_Models.txt\n",
      "Removed new lines from Contextual_Word_Representations_A_Contextual_Introduction.txt\n",
      "Removed new lines from BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation.txt\n",
      "Removed new lines from Reading_Wikipedia_to_Answer_Open_Domain_Questions.txt\n",
      "Removed new lines from NLP_Winter_2024_Course_Outline.txt\n",
      "Removed new lines from Natural_Language_Processing_Almost_from_Scratch.txt\n",
      "Removed new lines from lecture03_RNNs_and_LLMs.txt\n",
      "Removed new lines from BERT_Pre_training_of_Deep_Bidirectional_Transformers_for_Language_Understanding.txt\n",
      "Removed new lines from BI_DIRECTIONAL_ATTENTION_FLOW_FOR_MACHINE_COMPREHENSION.txt\n",
      "Removed new lines from lecture03_notes_dependencyparsing.txt\n",
      "Removed new lines from MUSIC_TRANSFORMER_GENERATING_MUSIC_WITH_LONG_TERM_STRUCTURE.txt\n",
      "Removed new lines from lecture02_Neural_Nets.txt\n",
      "Removed new lines from SEP775_FinalProjects_2.txt\n",
      "Removed new lines from lecture06_Transformers.txt\n",
      "Removed new lines from Understanding_LSTM_Networks.txt\n",
      "Removed new lines from Learning_Dense_Representations_of_Phrases_at_Scale.txt\n",
      "Removed new lines from SQuAD_100_000_Questions_for_Machine_Comprehension_of_Text.txt\n",
      "Removed new lines from SEP775_CodingExercise.txt\n",
      "Removed new lines from Language_Models_are_Few_Shot_Learners.txt\n",
      "Removed new lines from Evaluation_methods_for_unsupervised_word_embeddings.txt\n",
      "Removed new lines from lecture06_notes_self_attention_transformers.txt\n",
      "Removed new lines from lecture01_notes_wordvecs2.txt\n",
      "Removed new lines from lecture07_Prompting_Instruction_Finetuning_and_RLHF_.txt\n",
      "Removed new lines from Layer_Normalization.txt\n",
      "Removed new lines from Image_Transformer.txt\n",
      "Removed new lines from Fine_Tuning_and_Masked_Language_Models.txt\n",
      "Removed new lines from Dense_Passage_Retrieval_for_Open_Domain_Question_Answering.txt\n",
      "Removed new lines from Latent_Retrieval_for_Weakly_Supervised_Open_Domain_Question_Answering.txt\n",
      "Removed new lines from FINETUNED_LANGUAGE_MODELS_ARE_ZERO_SHOT_LEARNERS.txt\n",
      "Removed new lines from lecture08_Question_Answering.txt\n",
      "Removed new lines from Efficient_Estimation_of_Word_Representations_in_Vector_Space.txt\n",
      "Removed new lines from Chain_of_Thought_Prompting_Elicits_Reasoning_in_Large_Language_Models.txt\n",
      "Removed new lines from Attention_Is_All_You_Need.txt\n",
      "Removed new lines from lecture04_Conditioned_Generation.txt\n"
     ]
    }
   ],
   "source": [
    "# since there are still some new lines in the text files, we need to remove them\n",
    "# remove all new lines from the text files base a directory\n",
    "def remove_new_lines_from_text_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files = [f for f in files if f.endswith('.txt')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            text = f.read()\n",
    "        text = re.sub(r'\\n+', '', text)\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(text)\n",
    "        print(f'Removed new lines from {file}')\n",
    "\n",
    "remove_new_lines_from_text_files('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file name to lecture09 Multimodal Models\n",
      "Added file name to lecture01 notes Introduction\n",
      "Added file name to SEP775 Assignment4\n",
      "Added file name to GloVe Global Vectors for Word Representation\n",
      "Added file name to lecture05 Seq2Seq\n",
      "Added file name to gradient notes\n",
      "Added file name to lecture03 notes LM RNN\n",
      "Added file name to SEP775 Assignment2\n",
      "Added file name to lecture02 notes Backpropagation\n",
      "Added file name to Learning to summarize from human feedback\n",
      "Added file name to SEP775 python review 2024\n",
      "Added file name to lecture01 wordvecs1\n",
      "Added file name to Distributed Representations of Words and Phrases and their Compositionality\n",
      "Added file name to SEP775 Assignment3\n",
      "Added file name to Improving Distributional Similarity with Lessons Learned from Word Embeddings\n",
      "Added file name to On the difficulty of training Recurrent Neural Networks\n",
      "Added file name to SEP775 Assignment1\n",
      "Added file name to N gram Language Models\n",
      "Added file name to Contextual Word Representations A Contextual Introduction\n",
      "Added file name to BLEU a Method for Automatic Evaluation of Machine Translation\n",
      "Added file name to Reading Wikipedia to Answer Open Domain Questions\n",
      "Added file name to NLP Winter 2024 Course Outline\n",
      "Added file name to Natural Language Processing Almost from Scratch\n",
      "Added file name to lecture03 RNNs and LLMs\n",
      "Added file name to BERT Pre training of Deep Bidirectional Transformers for Language Understanding\n",
      "Added file name to BI DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION\n",
      "Added file name to lecture03 notes dependencyparsing\n",
      "Added file name to MUSIC TRANSFORMER GENERATING MUSIC WITH LONG TERM STRUCTURE\n",
      "Added file name to lecture02 Neural Nets\n",
      "Added file name to SEP775 FinalProjects 2\n",
      "Added file name to lecture06 Transformers\n",
      "Added file name to Understanding LSTM Networks\n",
      "Added file name to Learning Dense Representations of Phrases at Scale\n",
      "Added file name to SQuAD 100 000 Questions for Machine Comprehension of Text\n",
      "Added file name to SEP775 CodingExercise\n",
      "Added file name to Language Models are Few Shot Learners\n",
      "Added file name to Evaluation methods for unsupervised word embeddings\n",
      "Added file name to lecture06 notes self attention transformers\n",
      "Added file name to lecture01 notes wordvecs2\n",
      "Added file name to lecture07 Prompting Instruction Finetuning and RLHF \n",
      "Added file name to Layer Normalization\n",
      "Added file name to Image Transformer\n",
      "Added file name to Fine Tuning and Masked Language Models\n",
      "Added file name to Dense Passage Retrieval for Open Domain Question Answering\n",
      "Added file name to Latent Retrieval for Weakly Supervised Open Domain Question Answering\n",
      "Added file name to FINETUNED LANGUAGE MODELS ARE ZERO SHOT LEARNERS\n",
      "Added file name to lecture08 Question Answering\n",
      "Added file name to Efficient Estimation of Word Representations in Vector Space\n",
      "Added file name to Chain of Thought Prompting Elicits Reasoning in Large Language Models\n",
      "Added file name to Attention Is All You Need\n",
      "Added file name to lecture04 Conditioned Generation\n"
     ]
    }
   ],
   "source": [
    "# add file name to the beginning of each file\n",
    "def add_file_name_to_text_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files = [f for f in files if f.endswith('.txt')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            text = f.read()\n",
    "        # replace underscores with spaces\n",
    "        file = re.sub(r'_', ' ', file)\n",
    "        # remove .txt\n",
    "        file = re.sub(r'\\.txt', '', file)\n",
    "        text = f'file name: {file}. {text}'\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(text)\n",
    "        print(f'Added file name to {file}')\n",
    "\n",
    "add_file_name_to_text_files('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
